#fin=open("assign1/corpus_sample/19.txt","r")
#fin
from __future__ import print_function
#nltk.download('punkt')
import nltk

from nltk.tokenize import word_tokenize
with open ('assign1/corpus_sample/19.txt') as fin, open('word_freq/19.txt','w') as fout:
    for line in fin:
        tokens = word_tokenize(line)
        print(' '.join(tokens), end='\n', file=fout)
print(fout)
