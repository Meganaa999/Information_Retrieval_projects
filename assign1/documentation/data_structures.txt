1. document_tokenizer.py
    documentFiles : List of strings which has names of all files in Corpus.
    document_tokens_list : A list of Lists of strings which stores the final tokens of corpus Document-wise.
         
2. term_frequency_generator.py
    vocabulary : Dictionary consisting of Unique words(strings) as key, and their frequency(int) in corpus as values.
    term_frequency : List of Dictionaries - having key as words, and values as term frequency per Document


3. tf-idf.py
    vocabulary_idf : Dictionary consisting of unique words from vocabulary as tokens and The document frequenices as the values
    tf_idf_per_word : Dictionary of Dictionaries -> Dictionary with key as vocabulary words 
                                                    -> Dictionary with key as Document index
                                                        -> Value as Corresponding tf-idf values.    

4. query_tokenizer.py
    i. preprocessing(query)
        queryfin : A set to store the processed unique tokens from the query

    ii. find_rank_doc(query)
        score_final : A Dictionary to store the final weighted scores of each document based on tf-idf scores of input query tokens

5. frontend.py
    i. result()
        html : A string to store the html code for the results webpage

    ii. find_dict_meaning(query_new)
        dict_meaning : A Dictionary that stores the corresponding meaning for each input query token ( Using module PyDictionary)    